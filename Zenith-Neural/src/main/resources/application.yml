#
# Copyright 2017 George Belden
# 
# This file is part of Zenith.
# 
# Zenith is free software: you can redistribute it and/or modify it under
# the terms of the GNU General Public License as published by the Free Software
# Foundation, either version 3 of the License, or (at your option) any later
# version.
# 
# Zenith is distributed in the hope that it will be useful, but WITHOUT ANY
# WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR
# A PARTICULAR PURPOSE. See the GNU General Public License for more details.
# 
# You should have received a copy of the GNU General Public License along with
# Zenith. If not, see <http://www.gnu.org/licenses/>.
#

spring:
  profiles:
    active: mnist

# ---------------------------------------
# Spring Concurrency Properties
# ---------------------------------------
# The taskExecutor.poolSize.override property can be set to override the number of threads
# (defaults to the number of available cores of the system)
taskExecutor:
  queueCapacity: 1000000
  poolSize:
    #override:

---

spring:
  profiles: xor

network:
  layers:
    input: 2
    # The hidden layer takes a comma-separated list of integer:function value pairs representing the number of neurons per hidden layer followed by the activation function type
    hidden: 3:LEAKY_RELU
    output: 1:LEAKY_RELU
  bias:
    weight: 1.0
  trainingSamples:
    count: 10000
  testSamples:
    count: 1000
  learningRate: 0.1
  epochs: 1
  batchSize: 1
  weightDecay: 0.0
  output:
    fileName: /Users/george/Desktop/network-xor.json

---

spring:
  profiles: mnist

network:
  layers:
    input: 784
    # The hidden layer takes a comma-separated list of integer:function value pairs representing the number of neurons per hidden layer followed by the activation function type
    hidden: 98:LEAKY_RELU
    output: 10:SOFTMAX
  bias:
    weight: 1.0
  trainingSamples:
    count: 60000
  testSamples:
    count: 10000
  #learningRate: 0.00005  #this seems to work well with two hidden layers, albeit still not as good as a single layer for some reason
  learningRate: 0.01
  epochs: 1
  batchSize: 1
  weightDecay: 0.00
  output:
    fileName: /Users/george/Desktop/network-mnist.json

task:
  mnist:
    directory:
      trainingImages: /Users/george/Desktop/MNIST/train-images-idx3-ubyte/train-images.idx3-ubyte
      trainingLabels: /Users/george/Desktop/MNIST/train-labels-idx1-ubyte/train-labels.idx1-ubyte
      testImages: /Users/george/Desktop/MNIST/t10k-images-idx3-ubyte/t10k-images.idx3-ubyte
      testLabels: /Users/george/Desktop/MNIST/t10k-labels-idx1-ubyte/t10k-labels.idx1-ubyte
